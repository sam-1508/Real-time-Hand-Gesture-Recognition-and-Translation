# Real-time-Hand-Gesture-Recognition-and-Translation

Libraries Needed
Install the following by using ```pip install```

1. tensorflow
2. mediapipe
3. opencv-python
4. numpy
5. googletrans==4.0.0-rc1
6. streamlit
7. keras 
   
**Dataset and training:**
1. Pre-trained model is used here 
2. Mediapipe dataset is used.

**Mediapipe**

MediaPipe is an open-source framework for building pipelines to perform computer vision inference over arbitrary sensory data such as video or audio. Using MediaPipe, such a perception pipeline can be built as a graph of modular components.

Run the ```hand gesture.ipynb``` notenook to get a prediction alone 

To run the web app with translation to other language

```streamlit run app.py```

The app translates the predictions into 4 languages 
1. German
2. French
3. Tamil
4. Spanish

**SCREENSHOTS**

<img width="400" alt="Screenshot 2023-11-05 194958" src="https://github.com/sam-1508/Real-time-Hand-Gesture-Recognition-and-Translation/assets/125907034/17fe8bfa-0ca3-477d-931c-e0e25f08001d">
<img width="400" alt="Screenshot 2023-11-05 194556" src="https://github.com/sam-1508/Real-time-Hand-Gesture-Recognition-and-Translation/assets/125907034/947e81d5-edaa-4f15-821f-b00bb2d245eb">
<img width="400" alt="Screenshot 2024-01-02 135820" src="https://github.com/sam-1508/Real-time-Hand-Gesture-Recognition-and-Translation/assets/125907034/772bd082-6171-4662-b65d-cc9b173546d9">
